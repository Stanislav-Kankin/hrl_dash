import aiohttp
import os
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
import aiosqlite

logger = logging.getLogger(__name__)

class BitrixService:
    def __init__(self):
        self.webhook_url = os.getenv("BITRIX_WEBHOOK_URL")
        self.session = None
        self._cache = {}
        self._cache_ttl = 10 * 60
        self.executor = ThreadPoolExecutor(max_workers=5)
        
    async def ensure_session(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        if self.session is None or self.session.closed:
            timeout = aiohttp.ClientTimeout(total=120)
            self.session = aiohttp.ClientSession(timeout=timeout)

    async def close_session(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é"""
        if self.session and not self.session.closed:
            await self.session.close()
            self.session = None

    async def make_bitrix_request(self, method: str, params: Dict = None) -> Optional[Dict]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Bitrix24 API"""
        if not self.webhook_url:
            logger.error("BITRIX_WEBHOOK_URL –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return None

        await self.ensure_session()
        url = f"{self.webhook_url}/{method}"
        
        logger.info(f"üîç Bitrix API Request: {method}")
        if params:
            logger.info(f"üîç Params keys: {list(params.keys())}")
            if 'filter[ASSIGNED_BY_ID]' in params:
                logger.info(f"üîç ASSIGNED_BY_ID filter: {params['filter[ASSIGNED_BY_ID]']}")
        
        try:
            async with self.session.get(url, params=params) as response:
                logger.info(f"üîç Response status: {response.status}")
                if response.status == 200:
                    data = await response.json()
                    if 'result' in data:
                        logger.info(f"üîç Bitrix API Success: got {len(data['result'])} results")
                        return data['result']
                    elif 'error' in data:
                        logger.error(f"Bitrix API error: {data['error']}")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"HTTP error {response.status} for {url}: {error_text}")
                    return None
        except asyncio.TimeoutError:
            logger.error(f"Timeout error for method {method}")
            return None
        except Exception as e:
            logger.error(f"Request error: {str(e)}")
            return None

    async def test_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Bitrix24"""
        try:
            result = await self.make_bitrix_request("user.current")
            return result is not None
        except Exception as e:
            logger.error(f"Connection test failed: {str(e)}")
            return False

    async def get_user_by_id(self, user_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID"""
        try:
            params = {'ID': user_id}
            users = await self.make_bitrix_request("user.get", params)
            return users[0] if users and len(users) > 0 else None
        except Exception as e:
            logger.error(f"Error getting user by ID {user_id}: {str(e)}")
            return None

    async def get_presales_users(self) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø—Ä–µ—Å–µ–π–ª–∞ –ø–æ –∂—ë—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω—ã–º ID —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            cache_key = "presales_users"
            if cache_key in self._cache:
                cache_time, cached_data = self._cache[cache_key]
                if (datetime.now() - cache_time).total_seconds() < self._cache_ttl:
                    return cached_data

            known_presales_ids = ['8860', '8988', '17087', '17919', '17395', '18065']
            presales_users = []
            for user_id in known_presales_ids:
                user = await self.get_user_by_id(user_id)
                if user:
                    presales_users.append(user)
                else:
                    logger.warning(f"Presales user ID {user_id} not found in Bitrix24")

            self._cache[cache_key] = (datetime.now(), presales_users)
            return presales_users
        except Exception as e:
            logger.error(f"Error in get_presales_users: {str(e)}")
            return None

    async def get_activities(
        self,
        days: int = None,
        start_date: str = None,
        end_date: str = None,
        user_ids: List[str] = None,
        activity_types: List[str] = None
    ) -> Optional[List[Dict]]:
        """–û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î - –ø–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π –ë–ï–ó –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ô"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
            if start_date and end_date:
                start_date_obj = datetime.fromisoformat(start_date)
                end_date_obj = datetime.fromisoformat(end_date)
                start_date_obj = start_date_obj.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date_obj = end_date_obj.replace(hour=23, minute=59, second=59, microsecond=999999)
                
                total_days = (end_date_obj - start_date_obj).days + 1
                logger.info(f"üìÖ Loading activities for {total_days} days")
                        
            elif days:
                end_date_obj = datetime.now().replace(hour=23, minute=59, second=59, microsecond=999999)
                start_date_obj = (end_date_obj - timedelta(days=days)).replace(hour=0, minute=0, second=0, microsecond=0)
                logger.info(f"üìÖ Loading activities for {days} days")
            else:
                end_date_obj = datetime.now().replace(hour=23, minute=59, second=59, microsecond=999999)
                start_date_obj = (end_date_obj - timedelta(days=30)).replace(hour=0, minute=0, second=0, microsecond=0)
                logger.info(f"üìÖ Loading activities for 30 days (default)")

            start_date_str = start_date_obj.strftime("%Y-%m-%dT%H:%M:%S")
            end_date_str = end_date_obj.strftime("%Y-%m-%dT%H:%M:%S")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø–æ –∫–∞–∫–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å
            final_user_ids = None
            if user_ids and user_ids != ["all"]:
                final_user_ids = [str(uid) for uid in user_ids]
            else:
                presales = await self.get_presales_users()
                if presales:
                    final_user_ids = [str(user["ID"]) for user in presales]

            logger.info(f"üîç get_activities: user_ids={final_user_ids}, start_date={start_date_str}, end_date={end_date_str}")

            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            all_activities = []
            
            if final_user_ids:
                tasks = []
                for user_id in final_user_ids:
                    task = self._get_activities_for_single_user(
                        user_id, start_date_str, end_date_str, activity_types
                    )
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for i, user_activities in enumerate(results):
                    if isinstance(user_activities, Exception):
                        logger.error(f"Error getting activities for user {final_user_ids[i]}: {user_activities}")
                    elif user_activities:
                        all_activities.extend(user_activities)
                        logger.info(f"üîç User {final_user_ids[i]}: got {len(user_activities)} activities")

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π
            filtered_activities = await self._filter_completed_activities(all_activities)
            
            logger.info(f"üìä FINAL ACTIVITIES: {len(all_activities)} total, {len(filtered_activities)} completed")

            # –ü—Ä–æ–≤–µ—Ä–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
            if filtered_activities:
                user_distribution = {}
                for act in filtered_activities:
                    user_id = str(act.get('AUTHOR_ID', ''))
                    user_distribution[user_id] = user_distribution.get(user_id, 0) + 1
                logger.info(f"üìä Completed activities by user: {user_distribution}")

            return filtered_activities

        except Exception as e:
            logger.error(f"Error in get_activities: {str(e)}")
            return None

    async def _get_activities_for_single_user(
        self, 
        user_id: str, 
        start_date_str: str, 
        end_date_str: str, 
        activity_types: List[str] = None
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –° –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø–ú–ò"""
        user_activities = []
        start = 0
        request_count = 0
        max_requests = 20
        max_activities_per_user = 500

        while request_count < max_requests and len(user_activities) < max_activities_per_user:
            params = {
                'filter[>=CREATED]': start_date_str,
                'filter[<=CREATED]': end_date_str,
                'filter[AUTHOR_ID]': user_id,
                'start': start,
                'order[CREATED]': 'DESC'
            }

            if activity_types:
                params['filter[TYPE_ID]'] = activity_types

            activities = await self.make_bitrix_request("crm.activity.list", params)
            if activities is None:
                break
            if not activities:
                break

            user_activities.extend(activities)
            logger.info(f"üîç User {user_id} - Batch {request_count + 1}: got {len(activities)} activities, total: {len(user_activities)}")

            if len(user_activities) >= max_activities_per_user:
                logger.warning(f"‚ö†Ô∏è User {user_id} reached activity limit ({max_activities_per_user}), stopping")
                user_activities = user_activities[:max_activities_per_user]
                break

            if len(activities) < 50:
                logger.info(f"üîç User {user_id} - Last batch had {len(activities)} items, stopping pagination.")
                break

            start += 50
            request_count += 1
            await asyncio.sleep(0.2)

        logger.info(f"üîç User {user_id} - COMPLETED: {len(user_activities)} total activities")
        return user_activities

    async def _filter_completed_activities(self, activities: List[Dict]) -> List[Dict]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ - –£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø –ë–ï–ó –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ß"""
        if not activities:
            return []

        completed_activities = []
        
        for activity in activities:
            type_id = str(activity.get('TYPE_ID'))
            
            if type_id == '4':
                completed_activities.append(activity)
            else:
                completed_activities.append(activity)
        
        logger.info(f"üìä Simplified filter: {len(activities)} -> {len(completed_activities)} activities")
        return completed_activities

    async def get_activity_statistics(
        self,
        days: int = None,
        start_date: str = None,
        end_date: str = None,
        user_ids: List[str] = None
    ) -> Dict[str, Any]:
        activities = await self.get_activities(days=days, start_date=start_date, end_date=end_date, user_ids=user_ids)
        if not activities:
            return {}

        daily_stats = {}
        hourly_stats = {str(i).zfill(2): 0 for i in range(24)}
        type_stats = {}
        weekday_stats = {
            'Monday': 0, 'Tuesday': 0, 'Wednesday': 0, 'Thursday': 0,
            'Friday': 0, 'Saturday': 0, 'Sunday': 0
        }

        for activity in activities:
            created_str = activity['CREATED'].replace('Z', '+00:00')
            activity_date = datetime.fromisoformat(created_str)
            date_key = activity_date.strftime('%Y-%m-%d')
            hour_key = activity_date.strftime('%H')
            weekday = activity_date.strftime('%A')
            type_id = str(activity['TYPE_ID'])

            if date_key not in daily_stats:
                daily_stats[date_key] = {'date': date_key, 'day_of_week': weekday, 'total': 0, 'by_type': {}}

            daily_stats[date_key]['total'] += 1
            daily_stats[date_key]['by_type'][type_id] = daily_stats[date_key]['by_type'].get(type_id, 0) + 1
            type_stats[type_id] = type_stats.get(type_id, 0) + 1
            hourly_stats[hour_key] += 1
            weekday_stats[weekday] += 1

        sorted_daily = sorted(daily_stats.values(), key=lambda x: x['date'])

        return {
            'total_activities': len(activities),
            'daily_stats': sorted_daily,
            'hourly_stats': hourly_stats,
            'type_stats': type_stats,
            'weekday_stats': weekday_stats,
            'date_range': {
                'start': sorted_daily[0]['date'] if sorted_daily else '',
                'end': sorted_daily[-1]['date'] if sorted_daily else ''
            }
        }

    async def get_activity_statistics_from_activities(self, activities: List[Dict], start_date: str, end_date: str) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ –≥–æ—Ç–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π (–¥–ª—è –∫—ç—à–∞)"""
        if not activities:
            return {}

        daily_stats = {}
        hourly_stats = {str(i).zfill(2): 0 for i in range(24)}
        type_stats = {}
        weekday_stats = {
            'Monday': 0, 'Tuesday': 0, 'Wednesday': 0, 'Thursday': 0,
            'Friday': 0, 'Saturday': 0, 'Sunday': 0
        }

        for activity in activities:
            created_str = activity['CREATED'].replace('Z', '+00:00')
            activity_date = datetime.fromisoformat(created_str)
            date_key = activity_date.strftime('%Y-%m-%d')
            hour_key = activity_date.strftime('%H')
            weekday = activity_date.strftime('%A')
            type_id = str(activity['TYPE_ID'])

            if date_key not in daily_stats:
                daily_stats[date_key] = {'date': date_key, 'day_of_week': weekday, 'total': 0, 'by_type': {}}

            daily_stats[date_key]['total'] += 1
            daily_stats[date_key]['by_type'][type_id] = daily_stats[date_key]['by_type'].get(type_id, 0) + 1
            type_stats[type_id] = type_stats.get(type_id, 0) + 1
            hourly_stats[hour_key] += 1
            weekday_stats[weekday] += 1

        sorted_daily = sorted(daily_stats.values(), key=lambda x: x['date'])

        return {
            'total_activities': len(activities),
            'daily_stats': sorted_daily,
            'hourly_stats': hourly_stats,
            'type_stats': type_stats,
            'weekday_stats': weekday_stats,
            'date_range': {
                'start': sorted_daily[0]['date'] if sorted_daily else start_date,
                'end': sorted_daily[-1]['date'] if sorted_daily else end_date
            }
        }

    async def get_deals(
        self,
        start_date: str = None,
        end_date: str = None,
        user_ids: List[str] = None,
        limit: int = None
    ) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ —Å–¥–µ–ª–æ–∫ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        try:
            logger.info(f"üìä Starting deals loading: start_date={start_date}, end_date={end_date}, users={user_ids}")
            
            # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ user_ids, –¥–µ–ª–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
            if user_ids and len(user_ids) > 1:
                logger.info(f"üìä Multiple users detected ({len(user_ids)}), making separate requests")
                
                all_deals = []
                for user_id in user_ids:
                    logger.info(f"üìä Loading deals for user {user_id}")
                    user_deals = await self._get_deals_for_single_user(
                        user_id, start_date, end_date, limit
                    )
                    if user_deals:
                        all_deals.extend(user_deals)
                        logger.info(f"üìä User {user_id}: loaded {len(user_deals)} deals")
                    await asyncio.sleep(0.1)
                
                logger.info(f"üìä Multiple users loading COMPLETED: {len(all_deals)} total deals")
                
                if not all_deals:
                    return []
                
                return await self._enrich_deals_with_stages(all_deals)
            
            # üî• –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∫–æ–¥ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞
            all_deals = []
            start = 0
            total_loaded = 0
            
            while True:
                params = {
                    'select[]': ['ID', 'TITLE', 'STAGE_ID', 'ASSIGNED_BY_ID', 'DATE_CREATE', 'DATE_MODIFY', 'OPPORTUNITY', 'CURRENCY_ID', 'TYPE_ID', 'STATUS_ID'],
                    'start': start
                }

                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –¥–∞—Ç–µ
                if start_date and end_date:
                    try:
                        start_date_obj = datetime.fromisoformat(start_date)
                        end_date_obj = datetime.fromisoformat(end_date)
                        params['filter[>=DATE_CREATE]'] = start_date_obj.strftime("%Y-%m-%d")
                        params['filter[<=DATE_CREATE]'] = end_date_obj.strftime("%Y-%m-%d")
                    except Exception as e:
                        logger.error(f"Error parsing dates: {e}")

                # üî• –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
                if user_ids and len(user_ids) == 1:
                    params['filter[ASSIGNED_BY_ID]'] = user_ids[0]
                elif user_ids and len(user_ids) > 1:
                    params['filter[ASSIGNED_BY_ID]'] = user_ids

                logger.info(f"üìä Making Bitrix request for deals, start={start}")
                deals = await self.make_bitrix_request("crm.deal.list", params)
                
                if not deals:
                    logger.info("üìä No more deals found")
                    break

                all_deals.extend(deals)
                total_loaded += len(deals)
                
                batch_number = start // 50 + 1
                logger.info(f"üìä Batch {batch_number}: got {len(deals)} deals, total: {total_loaded}")

                if total_loaded % 500 == 0:
                    logger.info(f"üìä Progress: {total_loaded} deals loaded...")

                if total_loaded >= 5000:
                    logger.warning(f"‚ö†Ô∏è Reached large dataset limit ({total_loaded} deals). Consider filtering by date.")
                    break

                if limit and total_loaded >= limit:
                    logger.info(f"üìä Reached user limit of {limit} deals")
                    all_deals = all_deals[:limit]
                    break

                if len(deals) < 50:
                    logger.info("üìä Last batch (less than 50 items)")
                    break

                start += 50
                await asyncio.sleep(0.1)

            logger.info(f"üìä Deal loading COMPLETED: {len(all_deals)} total deals")

            if not all_deals:
                return []

            return await self._enrich_deals_with_stages(all_deals)

        except Exception as e:
            logger.error(f"‚ùå Error getting deals: {str(e)}", exc_info=True)
            return None

    async def _get_deals_for_single_user(
        self,
        user_id: str,
        start_date: str = None,
        end_date: str = None,
        limit: int = None
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        try:
            user_deals = []
            start = 0
            total_loaded = 0
            
            while True:
                params = {
                    'select[]': ['ID', 'TITLE', 'STAGE_ID', 'ASSIGNED_BY_ID', 'DATE_CREATE', 'DATE_MODIFY', 'OPPORTUNITY', 'CURRENCY_ID', 'TYPE_ID', 'STATUS_ID'],
                    'filter[ASSIGNED_BY_ID]': user_id,
                    'start': start
                }

                if start_date and end_date:
                    try:
                        start_date_obj = datetime.fromisoformat(start_date)
                        end_date_obj = datetime.fromisoformat(end_date)
                        params['filter[>=DATE_CREATE]'] = start_date_obj.strftime("%Y-%m-%d")
                        params['filter[<=DATE_CREATE]'] = end_date_obj.strftime("%Y-%m-%d")
                    except Exception as e:
                        logger.error(f"Error parsing dates: {e}")

                deals = await self.make_bitrix_request("crm.deal.list", params)
                
                if not deals:
                    break

                user_deals.extend(deals)
                total_loaded += len(deals)

                if limit and total_loaded >= limit:
                    user_deals = user_deals[:limit]
                    break

                if len(deals) < 50:
                    break

                start += 50
                await asyncio.sleep(0.1)

            logger.info(f"üìä User {user_id}: loaded {len(user_deals)} deals")
            return user_deals

        except Exception as e:
            logger.error(f"Error getting deals for user {user_id}: {str(e)}")
            return []

    async def _enrich_deals_with_stages(self, deals: List[Dict]) -> List[Dict]:
        """–û–±–æ–≥–∞—â–∞–µ—Ç —Å–¥–µ–ª–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Å—Ç–∞–¥–∏—è—Ö"""
        if not deals:
            return []

        all_stages = await self.get_deal_stages()
        stage_map = {}
        for stage in all_stages:
            stage_id = stage.get('STATUS_ID')
            stage_map[stage_id] = stage
        
        enriched_deals = []
        for deal in deals:
            stage_id = deal.get('STAGE_ID')
            type_id = deal.get('TYPE_ID')
            status_id = deal.get('STATUS_ID')
            
            stage_info = None
            for potential_id in [stage_id, type_id, status_id]:
                if potential_id and potential_id in stage_map:
                    stage_info = stage_map[potential_id]
                    break
            
            if not stage_info:
                stage_info = {
                    'NAME': stage_id or '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ',
                    'COLOR': '#cccccc',
                    'ENTITY_ID': 'UNKNOWN'
                }
            
            enriched_deals.append({
                'ID': deal.get('ID'),
                'TITLE': deal.get('TITLE'),
                'STAGE_ID': stage_id,
                'TYPE_ID': type_id,
                'STATUS_ID': status_id,
                'STAGE_NAME': stage_info.get('NAME', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                'STAGE_COLOR': stage_info.get('COLOR', '#cccccc'),
                'ENTITY_ID': stage_info.get('ENTITY_ID', 'UNKNOWN'),
                'ASSIGNED_BY_ID': deal.get('ASSIGNED_BY_ID'),
                'DATE_CREATE': deal.get('DATE_CREATE'),
                'DATE_MODIFY': deal.get('DATE_MODIFY'),
                'OPPORTUNITY': deal.get('OPPORTUNITY'),
                'CURRENCY_ID': deal.get('CURRENCY_ID')
            })

        # üî• –î–û–ë–ê–í–õ–Ø–ï–ú –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –†–ê–°–ü–†–ï–î–ï–õ–ï–ù–ò–Ø –ü–û –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø–ú
        user_distribution = {}
        for deal in enriched_deals:
            user_id = deal['ASSIGNED_BY_ID']
            user_distribution[user_id] = user_distribution.get(user_id, 0) + 1
        
        logger.info(f"üìä Final user distribution in deals: {user_distribution}")

        return enriched_deals

    async def get_deals_statistics_enhanced(
        self,
        start_date: str = None,
        end_date: str = None,
        user_ids: List[str] = None
    ) -> Dict[str, Any]:
        """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–¥–µ–ª–∫–∞–º —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π"""
        try:
            deals = await self.get_deals(start_date, end_date, user_ids)
            if not deals:
                return {
                    'total_deals': 0,
                    'total_value': 0,
                    'deals_by_stage': [],
                    'deals_by_type': []
                }

            stage_stats = {}
            type_stats = {}
            total_value = 0

            for deal in deals:
                stage_id = deal['STAGE_ID']
                stage_name = deal['STAGE_NAME']
                stage_color = deal['STAGE_COLOR']
                type_id = deal['TYPE_ID']
                value = float(deal.get('OPPORTUNITY', 0) or 0)

                if stage_name not in stage_stats:
                    stage_stats[stage_name] = {
                        'count': 0,
                        'value': 0,
                        'color': stage_color
                    }
                stage_stats[stage_name]['count'] += 1
                stage_stats[stage_name]['value'] += value

                if type_id not in type_stats:
                    type_stats[type_id] = {
                        'count': 0,
                        'value': 0
                    }
                type_stats[type_id]['count'] += 1
                type_stats[type_id]['value'] += value

                total_value += value

            deals_by_stage = [
                {
                    'stage_name': stage_name,
                    'stage_color': stats['color'],
                    'count': stats['count'],
                    'value': stats['value']
                }
                for stage_name, stats in stage_stats.items()
            ]

            deals_by_stage.sort(key=lambda x: x['count'], reverse=True)

            return {
                'total_deals': len(deals),
                'total_value': total_value,
                'deals_by_stage': deals_by_stage,
                'deals_by_type': type_stats
            }

        except Exception as e:
            logger.error(f"Error getting enhanced deals statistics: {str(e)}")
            return {
                'total_deals': 0,
                'total_value': 0,
                'deals_by_stage': [],
                'deals_by_type': []
            }

    async def get_deal_stage_history(self, deal_id: str) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Å—Ç–∞–¥–∏–π —Å–¥–µ–ª–∫–∏"""
        try:
            timeline = await self.make_bitrix_request("crm.timeline.list", {
                'filter[ENTITY_ID]': deal_id,
                'filter[ENTITY_TYPE]': 'deal',
                'filter[TYPE_CATEGORY_ID]': '1'
            })
            
            if not timeline:
                return None
                
            stage_history = []
            for event in timeline:
                if event.get('TYPE_ID') == '1':
                    data = event.get('DATA', {})
                    if 'STAGE_ID' in data:
                        stage_history.append({
                            'date': event.get('CREATED'),
                            'stage_id': data['STAGE_ID'],
                            'stage_name': data.get('STAGE_NAME', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'),
                            'event_id': event.get('ID')
                        })
            
            return sorted(stage_history, key=lambda x: x['date'])
            
        except Exception as e:
            logger.error(f"Error getting deal stage history: {str(e)}")
            return None

    async def get_deal_stages(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –í–°–ï–• —Å—Ç–∞–¥–∏–π –∏ —Å—Ç–∞—Ç—É—Å–æ–≤ —Å–¥–µ–ª–æ–∫"""
        try:
            all_stages = []
            
            stages = await self.make_bitrix_request("crm.status.list", {
                'filter[ENTITY_ID]': 'DEAL_STAGE'
            })
            if stages:
                all_stages.extend(stages)
                logger.info(f"üìä Loaded {len(stages)} DEAL_STAGE stages")
            
            deal_types = await self.make_bitrix_request("crm.status.list", {
                'filter[ENTITY_ID]': 'DEAL_TYPE'
            })
            if deal_types:
                all_stages.extend(deal_types)
                logger.info(f"üìä Loaded {len(deal_types)} DEAL_TYPE stages")
            
            statuses = await self.make_bitrix_request("crm.status.list", {
                'filter[ENTITY_ID]': 'STATUS'
            })
            if statuses:
                all_stages.extend(statuses)
                logger.info(f"üìä Loaded {len(statuses)} STATUS stages")
            
            logger.info(f"üìä Total stages loaded: {len(all_stages)}")
            return all_stages
            
        except Exception as e:
            logger.error(f"Error getting deal stages: {str(e)}")
            return []

    async def get_deals_statistics(
        self,
        start_date: str = None,
        end_date: str = None,
        user_ids: List[str] = None
    ) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–¥–µ–ª–∫–∞–º - –£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø"""
        try:
            deals = await self.get_deals(start_date, end_date, user_ids)
            if not deals:
                return {
                    'total_deals': 0,
                    'total_value': 0,
                    'deals_by_stage': []
                }

            stage_stats = {}
            total_value = 0

            for deal in deals:
                stage_id = deal['STAGE_ID']
                value = float(deal.get('OPPORTUNITY', 0) or 0)

                if stage_id not in stage_stats:
                    stage_stats[stage_id] = {
                        'count': 0,
                        'value': 0,
                        'name': deal['STAGE_NAME'],
                        'color': deal['STAGE_COLOR']
                    }
                stage_stats[stage_id]['count'] += 1
                stage_stats[stage_id]['value'] += value
                total_value += value

            deals_by_stage = [
                {
                    'stage_id': stage_id,
                    'stage_name': stats['name'],
                    'stage_color': stats['color'],
                    'count': stats['count'],
                    'value': stats['value']
                }
                for stage_id, stats in stage_stats.items()
            ]

            return {
                'total_deals': len(deals),
                'total_value': total_value,
                'deals_by_stage': deals_by_stage
            }

        except Exception as e:
            logger.error(f"Error getting deals statistics: {str(e)}")
            return {
                'total_deals': 0,
                'total_value': 0,
                'deals_by_stage': []
            }

    async def get_user_deals(self, user_id: str) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        return await self.get_deals(user_ids=[user_id])
    
    async def get_all_users(self) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π Bitrix24"""
        try:
            cache_key = "all_users"
            if cache_key in self._cache:
                cache_time, cached_data = self._cache[cache_key]
                if (datetime.now() - cache_time).total_seconds() < self._cache_ttl:
                    return cached_data

            all_users = []
            start = 0
            
            while True:
                params = {
                    'start': start
                }
                
                users = await self.make_bitrix_request("user.get", params)
                if not users:
                    break
                    
                all_users.extend(users)
                
                if len(users) < 50:
                    break
                    
                start += 50
                await asyncio.sleep(0.1)

            self._cache[cache_key] = (datetime.now(), all_users)
            logger.info(f"‚úÖ Loaded {len(all_users)} users from Bitrix24")
            return all_users
            
        except Exception as e:
            logger.error(f"Error getting all users: {str(e)}")
            return None

    async def get_activities_optimized(
        self,
        start_date: str,
        end_date: str,
        user_ids: List[str] = None,
        activity_types: List[str] = None,
        chunk_size_days: int = 7
    ) -> Optional[List[Dict]]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤"""
        try:
            start_date_obj = datetime.fromisoformat(start_date)
            end_date_obj = datetime.fromisoformat(end_date)
            total_days = (end_date_obj - start_date_obj).days + 1
            
            logger.info(f"üìÖ OPTIMIZED Loading: {total_days} days, chunk size: {chunk_size_days} days")
            
            if total_days > 14:
                return await self._get_activities_chunked(
                    start_date_obj, end_date_obj, user_ids, activity_types, chunk_size_days
                )
            else:
                return await self.get_activities(
                    start_date=start_date,
                    end_date=end_date,
                    user_ids=user_ids,
                    activity_types=activity_types
                )
                
        except Exception as e:
            logger.error(f"Error in get_activities_optimized: {str(e)}")
            return None

    async def _get_activities_chunked(
            self,
            start_date: datetime,
            end_date: datetime,
            user_ids: List[str],
            activity_types: List[str],
            chunk_size_days: int
        ) -> List[Dict]:
            """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π –ø–æ —á–∞—Å—Ç—è–º"""
            all_activities = []
            current_start = start_date
            chunk_number = 1
            
            while current_start <= end_date:
                current_end = min(current_start + timedelta(days=chunk_size_days - 1), end_date)
                
                chunk_start_str = current_start.strftime("%Y-%m-%d")
                chunk_end_str = current_end.strftime("%Y-%m-%d")
                
                logger.info(f"üìÖ Chunk {chunk_number}: {chunk_start_str} to {chunk_end_str}")
                
                chunk_activities = await self.get_activities(
                    start_date=chunk_start_str,
                    end_date=chunk_end_str,
                    user_ids=user_ids,
                    activity_types=activity_types
                )
                
                if chunk_activities:
                    all_activities.extend(chunk_activities)
                    logger.info(f"üìÖ Chunk {chunk_number} completed: {len(chunk_activities)} activities")
                
                current_start = current_end + timedelta(days=1)
                chunk_number += 1
                
                await asyncio.sleep(1)
            
            logger.info(f"üìÖ All chunks completed: {len(all_activities)} total activities")
            return all_activities

    async def get_deals_with_timing(self, user_ids: List[str] = None, limit: int = 100) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ –≤—Ä–µ–º–µ–Ω–∏ –≤–∑—è—Ç–∏—è –≤ —Ä–∞–±–æ—Ç—É"""
        try:
            logger.info(f"‚è±Ô∏è Getting deals with timing info for users: {user_ids}")
            
            deals = await self.get_deals(user_ids=user_ids, limit=limit)
            if not deals:
                return []
            
            enriched_deals = []
            
            for deal in deals:
                deal_id = deal.get('ID')
                stage_id = deal.get('STAGE_ID')
                created_date = deal.get('DATE_CREATE')
                
                taken_to_work_date = await self._get_taken_to_work_date(deal_id, created_date)
                
                enriched_deal = {
                    **deal,
                    'taken_to_work_date': taken_to_work_date,
                    'is_in_work': taken_to_work_date is not None,
                    'days_in_work': self._calculate_days_in_work(taken_to_work_date) if taken_to_work_date else 0
                }
                
                enriched_deals.append(enriched_deal)
            
            logger.info(f"‚è±Ô∏è Enriched {len(enriched_deals)} deals with timing info")
            return enriched_deals
            
        except Exception as e:
            logger.error(f"Error getting deals with timing: {str(e)}")
            return None

    async def _get_taken_to_work_date(self, deal_id: str, created_date: str) -> Optional[str]:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –¥–∞—Ç—É –≤–∑—è—Ç–∏—è —Å–¥–µ–ª–∫–∏ –≤ —Ä–∞–±–æ—Ç—É"""
        try:
            initial_stages = ['NEW', 'PREPARATION', '1', 'C1', 'C1:NEW']
            
            history = await self.get_deal_stage_history(deal_id)
            if not history:
                return created_date
                
            for i, event in enumerate(history):
                current_stage = event.get('stage_id', '')
                stage_name = event.get('stage_name', '').lower()
                
                is_initial_stage = (
                    current_stage in initial_stages or
                    '–Ω–æ–≤' in stage_name or
                    '–ø–µ—Ä–≤–∏—á' in stage_name or
                    '–ø–æ–¥–≥–æ—Ç–æ–≤' in stage_name
                )
                
                is_in_work_stage = (
                    '–æ–±—Ä–∞–±–æ—Ç' in stage_name or
                    '–≤ —Ä–∞–±–æ—Ç–µ' in stage_name or
                    '–∫–ø' in stage_name or
                    '–∫–æ–º–º–µ—Ä—á' in stage_name
                )
                
                if not is_initial_stage or is_in_work_stage:
                    return event.get('date', created_date)
                    
            return created_date
            
        except Exception as e:
            logger.error(f"Error getting taken to work date: {e}")
            return created_date

    def _calculate_days_in_work(self, taken_to_work_date: str) -> int:
        """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–Ω–µ–π –≤ —Ä–∞–±–æ—Ç–µ"""
        try:
            if not taken_to_work_date:
                return 0
                
            work_date = datetime.fromisoformat(taken_to_work_date.replace('Z', '+00:00'))
            today = datetime.now()
            
            days = (today - work_date).days
            return max(0, days)
            
        except Exception as e:
            logger.error(f"Error calculating days in work: {e}")
            return 0

    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à"""
        self._cache.clear()
        logger.info("Cache cleared")