import aiohttp
import os
from datetime import datetime, timedelta
from typing import List, Optional, Dict, Any
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor
import aiosqlite

logger = logging.getLogger(__name__)

class BitrixService:
    def __init__(self):
        self.webhook_url = os.getenv("BITRIX_WEBHOOK_URL")
        self.session = None
        self._cache = {}
        self._cache_ttl = 10 * 60
        self.executor = ThreadPoolExecutor(max_workers=5)
        self.max_activities_per_user = 100000  # üî• –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π –Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        self.max_days_per_request = 100  # üî• –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –≤ –¥–Ω—è—Ö –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        
    async def ensure_session(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å–µ—Å—Å–∏—é –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç"""
        if self.session is None or self.session.closed:
            timeout = aiohttp.ClientTimeout(total=500)  # üî• –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç
            self.session = aiohttp.ClientSession(timeout=timeout)

    async def close_session(self):
        """–ó–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–µ—Å—Å–∏—é"""
        if self.session and not self.session.closed:
            await self.session.close()
            self.session = None

    async def make_bitrix_request(self, method: str, params: Dict = None) -> Optional[Dict]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å –∫ Bitrix24 API"""
        if not self.webhook_url:
            logger.error("BITRIX_WEBHOOK_URL –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return None

        await self.ensure_session()
        url = f"{self.webhook_url}/{method}"
        
        logger.info(f"üîç Bitrix API Request: {method}")
        if params:
            logger.info(f"üîç Params keys: {list(params.keys())}")
            if 'filter[AUTHOR_ID]' in params:
                logger.info(f"üîç AUTHOR_ID filter: {params['filter[AUTHOR_ID]']}")
        
        try:
            async with self.session.get(url, params=params) as response:
                logger.info(f"üîç Response status: {response.status}")
                if response.status == 200:
                    data = await response.json()
                    if 'result' in data:
                        logger.info(f"üîç Bitrix API Success: got {len(data['result'])} results")
                        return data['result']
                    elif 'error' in data:
                        logger.error(f"Bitrix API error: {data['error']}")
                        return None
                else:
                    error_text = await response.text()
                    logger.error(f"HTTP error {response.status} for {url}: {error_text}")
                    return None
        except asyncio.TimeoutError:
            logger.error(f"Timeout error for method {method}")
            return None
        except Exception as e:
            logger.error(f"Request error: {str(e)}")
            return None

    async def test_connection(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Bitrix24"""
        try:
            result = await self.make_bitrix_request("user.current")
            return result is not None
        except Exception as e:
            logger.error(f"Connection test failed: {str(e)}")
            return False

    async def get_user_by_id(self, user_id: str) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ ID"""
        try:
            params = {'ID': user_id}
            users = await self.make_bitrix_request("user.get", params)
            return users[0] if users and len(users) > 0 else None
        except Exception as e:
            logger.error(f"Error getting user by ID {user_id}: {str(e)}")
            return None

    async def get_presales_users(self) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –ø—Ä–µ—Å–µ–π–ª–∞ –ø–æ –∂—ë—Å—Ç–∫–æ –∑–∞–¥–∞–Ω–Ω—ã–º ID —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        try:
            cache_key = "presales_users"
            if cache_key in self._cache:
                cache_time, cached_data = self._cache[cache_key]
                if (datetime.now() - cache_time).total_seconds() < self._cache_ttl:
                    return cached_data

            known_presales_ids = ['8860', '8988', '17087', '17919', '17395', '18065']
            presales_users = []
            for user_id in known_presales_ids:
                user = await self.get_user_by_id(user_id)
                if user:
                    presales_users.append(user)
                else:
                    logger.warning(f"Presales user ID {user_id} not found in Bitrix24")

            self._cache[cache_key] = (datetime.now(), presales_users)
            return presales_users
        except Exception as e:
            logger.error(f"Error in get_presales_users: {str(e)}")
            return None

    async def get_activities(
        self,
        days: int = None,
        start_date: str = None,
        end_date: str = None,
        user_ids: List[str] = None,
        activity_types: List[str] = None
    ) -> Optional[List[Dict]]:
        """–û–°–ù–û–í–ù–û–ô –ú–ï–¢–û–î - –ø–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π —Å –û–ì–†–ê–ù–ò–ß–ï–ù–ò–Ø–ú–ò –¥–ª—è –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤"""
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç
            if start_date and end_date:
                start_date_obj = datetime.fromisoformat(start_date)
                end_date_obj = datetime.fromisoformat(end_date)
                start_date_obj = start_date_obj.replace(hour=0, minute=0, second=0, microsecond=0)
                end_date_obj = end_date_obj.replace(hour=23, minute=59, second=59, microsecond=999999)
                
                # üî• –ü–†–û–í–ï–†–ö–ê: –µ—Å–ª–∏ –ø–µ—Ä–∏–æ–¥ –±–æ–ª—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ - —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
                total_days = (end_date_obj - start_date_obj).days + 1
                if total_days > self.max_days_per_request:
                    logger.info(f"üìÖ Large period detected: {total_days} days, splitting into chunks...")
                    return await self._get_activities_large_period(
                        start_date_obj, end_date_obj, user_ids, activity_types
                    )
                    
            elif days:
                end_date_obj = datetime.now().replace(hour=23, minute=59, second=59, microsecond=999999)
                start_date_obj = (end_date_obj - timedelta(days=days)).replace(hour=0, minute=0, second=0, microsecond=0)
                
                # üî• –ü–†–û–í–ï–†–ö–ê –¥–ª—è –¥–Ω–µ–π
                if days > self.max_days_per_request:
                    logger.info(f"üìÖ Large period detected: {days} days, splitting into chunks...")
                    return await self._get_activities_large_period(
                        start_date_obj, end_date_obj, user_ids, activity_types
                    )
            else:
                end_date_obj = datetime.now().replace(hour=23, minute=59, second=59, microsecond=999999)
                start_date_obj = (end_date_obj - timedelta(days=30)).replace(hour=0, minute=0, second=0, microsecond=0)

            start_date_str = start_date_obj.strftime("%Y-%m-%dT%H:%M:%S")
            end_date_str = end_date_obj.strftime("%Y-%m-%dT%H:%M:%S")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –ø–æ –∫–∞–∫–∏–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å
            final_user_ids = None
            if user_ids and user_ids != ["all"]:
                final_user_ids = [str(uid) for uid in user_ids]
            else:
                presales = await self.get_presales_users()
                if presales:
                    final_user_ids = [str(user["ID"]) for user in presales]

            logger.info(f"üîç get_activities: user_ids={final_user_ids}, start_date={start_date_str}, end_date={end_date_str}")

            # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –≤—Å–µ—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
            all_activities = []
            
            if final_user_ids:
                tasks = []
                for user_id in final_user_ids:
                    task = self._get_activities_for_single_user(
                        user_id, start_date_str, end_date_str, activity_types
                    )
                    tasks.append(task)
                
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for i, user_activities in enumerate(results):
                    if isinstance(user_activities, Exception):
                        logger.error(f"Error getting activities for user {final_user_ids[i]}: {user_activities}")
                    elif user_activities:
                        all_activities.extend(user_activities)
                        logger.info(f"üîç User {final_user_ids[i]}: got {len(user_activities)} activities")

            # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π
            filtered_activities = await self._filter_completed_activities(all_activities)
            
            logger.info(f"üìä FINAL ACTIVITIES: {len(all_activities)} total, {len(filtered_activities)} completed")

            # –ü—Ä–æ–≤–µ—Ä–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º
            if filtered_activities:
                user_distribution = {}
                for act in filtered_activities:
                    user_id = str(act.get('AUTHOR_ID', ''))
                    user_distribution[user_id] = user_distribution.get(user_id, 0) + 1
                logger.info(f"üìä Completed activities by user: {user_distribution}")

            return filtered_activities

        except Exception as e:
            logger.error(f"Error in get_activities: {str(e)}")
            return None

    async def _get_activities_large_period(
        self, 
        start_date: datetime, 
        end_date: datetime, 
        user_ids: List[str], 
        activity_types: List[str] = None
    ) -> List[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–æ–ª—å—à–∏—Ö –ø–µ—Ä–∏–æ–¥–æ–≤ - —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —á–∞—Å—Ç–∏"""
        all_activities = []
        current_start = start_date
        
        while current_start <= end_date:
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–Ω–µ—Ü —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
            current_end = min(
                current_start + timedelta(days=self.max_days_per_request - 1), 
                end_date
            )
            
            logger.info(f"üìÖ Processing chunk: {current_start.strftime('%Y-%m-%d')} to {current_end.strftime('%Y-%m-%d')}")
            
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ —á–∞–Ω–∫–∞
            chunk_activities = await self._get_activities_for_period(
                current_start, current_end, user_ids, activity_types
            )
            
            if chunk_activities:
                all_activities.extend(chunk_activities)
                logger.info(f"üìÖ Chunk completed: {len(chunk_activities)} activities")
            
            # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É —á–∞–Ω–∫—É
            current_start = current_end + timedelta(days=1)
            
            # üî• –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞—Ç—å API
            await asyncio.sleep(1)
        
        logger.info(f"üìÖ Large period completed: {len(all_activities)} total activities")
        return all_activities

    async def _get_activities_for_period(
        self,
        start_date: datetime,
        end_date: datetime,
        user_ids: List[str],
        activity_types: List[str] = None
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–∏–æ–¥–∞"""
        start_date_str = start_date.strftime("%Y-%m-%dT%H:%M:%S")
        end_date_str = end_date.strftime("%Y-%m-%dT%H:%M:%S")
        
        all_activities = []
        
        if user_ids:
            tasks = []
            for user_id in user_ids:
                task = self._get_activities_for_single_user(
                    user_id, start_date_str, end_date_str, activity_types
                )
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for i, user_activities in enumerate(results):
                if isinstance(user_activities, Exception):
                    logger.error(f"Error getting activities for user {user_ids[i]}: {user_activities}")
                elif user_activities:
                    all_activities.extend(user_activities)
        
        return await self._filter_completed_activities(all_activities)

    async def _get_activities_for_single_user(
        self, 
        user_id: str, 
        start_date_str: str, 
        end_date_str: str, 
        activity_types: List[str] = None
    ) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π –¥–ª—è –æ–¥–Ω–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Å –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï–ú –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞"""
        user_activities = []
        start = 0
        request_count = 0
        max_requests = 20  # üî• –£–ú–ï–ù–¨–®–ê–ï–ú –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø—Ä–æ—Å–æ–≤ (1000 –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π)

        while request_count < max_requests:
            params = {
                'filter[>=CREATED]': start_date_str,
                'filter[<=CREATED]': end_date_str,
                'filter[AUTHOR_ID]': user_id,
                'start': start,
                'order[CREATED]': 'DESC'
            }

            if activity_types:
                params['filter[TYPE_ID]'] = activity_types

            activities = await self.make_bitrix_request("crm.activity.list", params)
            if activities is None:
                break
            if not activities:
                break

            user_activities.extend(activities)
            logger.info(f"üîç User {user_id} - Batch {request_count + 1}: got {len(activities)} activities, total: {len(user_activities)}")

            # üî• –ü–†–û–í–ï–†–ö–ê: –Ω–µ –ø—Ä–µ–≤—ã—Å–∏–ª–∏ –ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π
            if len(user_activities) >= self.max_activities_per_user:
                logger.warning(f"‚ö†Ô∏è User {user_id} reached activity limit ({self.max_activities_per_user}), stopping")
                break

            if len(activities) < 50:
                logger.info(f"üîç User {user_id} - Last batch had {len(activities)} items, stopping pagination.")
                break

            start += 50
            request_count += 1
            await asyncio.sleep(0.1)  # üî• –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É

        return user_activities

    async def _filter_completed_activities(self, activities: List[Dict]) -> List[Dict]:
        """–§–∏–ª—å—Ç—Ä—É–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ - –£–ü–†–û–©–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø –ë–ï–ó –ü–†–û–í–ï–†–ö–ò –ó–ê–î–ê–ß"""
        if not activities:
            return []

        completed_activities = []
        
        for activity in activities:
            type_id = str(activity.get('TYPE_ID'))
            
            # –î–ª—è –∑–∞–¥–∞—á –≤—Ä–µ–º–µ–Ω–Ω–æ —Å—á–∏—Ç–∞–µ–º –í–°–ï –∞–∫—Ç–∏–≤–Ω—ã–º–∏
            if type_id == '4':  # –ó–∞–¥–∞—á–∞
                completed_activities.append(activity)
            else:
                # –î–ª—è –∑–≤–æ–Ω–∫–æ–≤, –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∏ –≤—Å—Ç—Ä–µ—á —Å—á–∏—Ç–∞–µ–º –≤—Å–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–º–∏
                completed_activities.append(activity)
        
        logger.info(f"üìä Simplified filter: {len(activities)} -> {len(completed_activities)} activities")
        return completed_activities

    async def get_activity_statistics(
        self,
        days: int = None,
        start_date: str = None,
        end_date: str = None,
        user_ids: List[str] = None
    ) -> Dict[str, Any]:
        activities = await self.get_activities(days=days, start_date=start_date, end_date=end_date, user_ids=user_ids)
        if not activities:
            return {}

        daily_stats = {}
        hourly_stats = {str(i).zfill(2): 0 for i in range(24)}
        type_stats = {}
        weekday_stats = {
            'Monday': 0, 'Tuesday': 0, 'Wednesday': 0, 'Thursday': 0,
            'Friday': 0, 'Saturday': 0, 'Sunday': 0
        }

        for activity in activities:
            created_str = activity['CREATED'].replace('Z', '+00:00')
            activity_date = datetime.fromisoformat(created_str)
            date_key = activity_date.strftime('%Y-%m-%d')
            hour_key = activity_date.strftime('%H')
            weekday = activity_date.strftime('%A')
            type_id = str(activity['TYPE_ID'])

            if date_key not in daily_stats:
                daily_stats[date_key] = {'date': date_key, 'day_of_week': weekday, 'total': 0, 'by_type': {}}

            daily_stats[date_key]['total'] += 1
            daily_stats[date_key]['by_type'][type_id] = daily_stats[date_key]['by_type'].get(type_id, 0) + 1
            type_stats[type_id] = type_stats.get(type_id, 0) + 1
            hourly_stats[hour_key] += 1
            weekday_stats[weekday] += 1

        sorted_daily = sorted(daily_stats.values(), key=lambda x: x['date'])

        return {
            'total_activities': len(activities),
            'daily_stats': sorted_daily,
            'hourly_stats': hourly_stats,
            'type_stats': type_stats,
            'weekday_stats': weekday_stats,
            'date_range': {
                'start': sorted_daily[0]['date'] if sorted_daily else '',
                'end': sorted_daily[-1]['date'] if sorted_daily else ''
            }
        }
    
    async def get_activity_statistics_from_data(self, activities: List[Dict]) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏–∑ –≥–æ—Ç–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–µ–π (–±–µ–∑ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Bitrix)"""
        if not activities:
            return {}

        daily_stats = {}
        hourly_stats = {str(i).zfill(2): 0 for i in range(24)}
        type_stats = {}
        weekday_stats = {
            'Monday': 0, 'Tuesday': 0, 'Wednesday': 0, 'Thursday': 0,
            'Friday': 0, 'Saturday': 0, 'Sunday': 0
        }

        for activity in activities:
            created_str = activity['CREATED'].replace('Z', '+00:00')
            activity_date = datetime.fromisoformat(created_str)
            date_key = activity_date.strftime('%Y-%m-%d')
            hour_key = activity_date.strftime('%H')
            weekday = activity_date.strftime('%A')
            type_id = str(activity['TYPE_ID'])

            if date_key not in daily_stats:
                daily_stats[date_key] = {'date': date_key, 'day_of_week': weekday, 'total': 0, 'by_type': {}}

            daily_stats[date_key]['total'] += 1
            daily_stats[date_key]['by_type'][type_id] = daily_stats[date_key]['by_type'].get(type_id, 0) + 1
            type_stats[type_id] = type_stats.get(type_id, 0) + 1
            hourly_stats[hour_key] += 1
            weekday_stats[weekday] += 1

        sorted_daily = sorted(daily_stats.values(), key=lambda x: x['date'])

        return {
            'total_activities': len(activities),
            'daily_stats': sorted_daily,
            'hourly_stats': hourly_stats,
            'type_stats': type_stats,
            'weekday_stats': weekday_stats,
            'date_range': {
                'start': sorted_daily[0]['date'] if sorted_daily else '',
                'end': sorted_daily[-1]['date'] if sorted_daily else ''
            }
        }
    
    async def get_cached_activities_for_selected_users(self, selected_user_ids: List[str], start_date: str, end_date: str, activity_types: List[str] = None) -> Dict:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –ø–æ–ª–Ω–æ—Ç—É –∫—ç—à–∞ –¢–û–õ–¨–ö–û –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
        """
        try:
            async with aiosqlite.connect(self.db_path) as db:
                placeholders = ','.join('?' for _ in selected_user_ids)
                
                # –ë–∞–∑–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
                query = f'''
                    SELECT raw_data, data_date FROM activities_cache 
                    WHERE user_id IN ({placeholders}) 
                    AND data_date BETWEEN ? AND ?
                '''
                params = selected_user_ids + [start_date, end_date]
                
                # –§–∏–ª—å—Ç—Ä –ø–æ —Ç–∏–ø—É –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                if activity_types and activity_types != ['all']:
                    type_placeholders = ','.join('?' for _ in activity_types)
                    query += f' AND type_id IN ({type_placeholders})'
                    params.extend(activity_types)
                
                query += ' ORDER BY created DESC'
                
                cursor = await db.execute(query, params)
                rows = await cursor.fetchall()
                
                if not rows:
                    return {"activities": [], "missing_days": [], "completeness": 0, "selected_users": selected_user_ids}
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –¢–û–õ–¨–ö–û –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
                cached_dates = set()
                activities = []
                
                for row in rows:
                    try:
                        activity_data = json.loads(row[0])
                        # üî• –í–ê–ñ–ù–û: —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –≤ –∫—ç—à–µ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –¥—Ä—É–≥–∏—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
                        if str(activity_data.get('AUTHOR_ID')) in selected_user_ids:
                            activities.append(activity_data)
                            cached_dates.add(row[1])
                    except Exception as e:
                        continue
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –¥–Ω–∏
                start = datetime.fromisoformat(start_date)
                end = datetime.fromisoformat(end_date)
                total_days = (end - start).days + 1
                
                missing_days = []
                current = start
                while current <= end:
                    date_str = current.strftime("%Y-%m-%d")
                    if date_str not in cached_dates:
                        missing_days.append(date_str)
                    current += timedelta(days=1)
                
                completeness = ((total_days - len(missing_days)) / total_days) * 100
                
                logger.info(f"üìä Cache analysis for {len(selected_user_ids)} selected users: {len(activities)} activities, {completeness:.1f}% complete")
                
                return {
                    "activities": activities,
                    "missing_days": missing_days,
                    "completeness": completeness,
                    "cached_days_count": len(cached_dates),
                    "total_days": total_days,
                    "selected_users": selected_user_ids
                }
                    
        except Exception as e:
            logger.error(f"Error analyzing cache for selected users: {e}")
            return {"activities": [], "missing_days": [], "completeness": 0, "selected_users": selected_user_ids}

    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à"""
        self._cache.clear()
        logger.info("Cache cleared")